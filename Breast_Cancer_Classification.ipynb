{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9guuLJNGmk4S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "INPUT_DATASET = \"/content/drive/MyDrive/ Projects_Datasets/archive/\"\n",
        "\n",
        "BASE_PATH = \"/content/datasets/idc\"\n",
        "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
        "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
        "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
        "\n",
        "TRAIN_SPLIT = 0.8\n",
        "VAL_SPLIT = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from cancernet import config\n",
        "from imutils import paths\n",
        "import random, shutil, os\n",
        "\n",
        "originalPaths=list(paths.list_images(INPUT_DATASET))\n",
        "random.seed(7)\n",
        "random.shuffle(originalPaths)\n",
        "\n",
        "index=int(len(originalPaths)*TRAIN_SPLIT)\n",
        "trainPaths=originalPaths[:index]\n",
        "testPaths=originalPaths[index:]\n",
        "\n",
        "index=int(len(trainPaths)*VAL_SPLIT)\n",
        "valPaths=trainPaths[:index]\n",
        "trainPaths=trainPaths[index:]\n",
        "\n",
        "datasets=[(\"training\", trainPaths, TRAIN_PATH),\n",
        "          (\"validation\", valPaths, VAL_PATH),\n",
        "          (\"testing\", testPaths, TEST_PATH)\n",
        "]\n",
        "\n",
        "for (setType, originalPaths, basePath) in datasets:\n",
        "        print(f'Building {setType} set')\n",
        "\n",
        "        if not os.path.exists(basePath):\n",
        "                print(f'Building directory {BASE_PATH}')\n",
        "                os.makedirs(basePath)\n",
        "\n",
        "        for path in originalPaths:\n",
        "                file=path.split(os.path.sep)[-1]\n",
        "                label=file[-5:-4]\n",
        "\n",
        "                labelPath=os.path.sep.join([basePath,label])\n",
        "                if not os.path.exists(labelPath):\n",
        "                        print(f'Building directory {labelPath}')\n",
        "                        os.makedirs(labelPath)\n",
        "\n",
        "                newPath=os.path.sep.join([labelPath, file])\n",
        "                shutil.copy2(path, newPath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhvJkL-En2q8",
        "outputId": "e7be4d97-3df8-427d-a01e-4205983d9247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building training set\n",
            "Building directory /content/datasets/idc\n",
            "Building directory /content/datasets/idc/training/1\n",
            "Building directory /content/datasets/idc/training/0\n",
            "Building validation set\n",
            "Building directory /content/datasets/idc\n",
            "Building directory /content/datasets/idc/validation/1\n",
            "Building directory /content/datasets/idc/validation/0\n",
            "Building testing set\n",
            "Building directory /content/datasets/idc\n",
            "Building directory /content/datasets/idc/testing/0\n",
            "Building directory /content/datasets/idc/testing/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class CancerNet:\n",
        "  @staticmethod\n",
        "  def build(width,height,depth,classes):\n",
        "    model=Sequential()\n",
        "    shape=(height,width,depth)\n",
        "    channelDim=-1\n",
        "\n",
        "    if K.image_data_format()==\"channels_first\":\n",
        "      shape=(depth,height,width)\n",
        "      channelDim=1\n",
        "\n",
        "    model.add(SeparableConv2D(32, (3,3), padding=\"same\",input_shape=shape))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=channelDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(SeparableConv2D(64, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=channelDim))\n",
        "    model.add(SeparableConv2D(64, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=channelDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=channelDim))\n",
        "    model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=channelDim))\n",
        "    model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization(axis=channelDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "n9msJvD9n6fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import Adagrad\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from cancernet.cancernet import CancerNet\n",
        "#from cancernet import config\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "NUM_EPOCHS=40; INIT_LR=1e-2; BS=32\n",
        "\n",
        "trainPaths=list(paths.list_images(TRAIN_PATH))\n",
        "lenTrain=len(trainPaths)\n",
        "lenVal=len(list(paths.list_images(VAL_PATH)))\n",
        "lenTest=len(list(paths.list_images(TEST_PATH)))\n",
        "\n",
        "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
        "trainLabels=np_utils.to_categorical(trainLabels)\n",
        "classTotals=trainLabels.sum(axis=0)\n",
        "classWeight=classTotals.max()/classTotals\n",
        "\n",
        "trainAug = ImageDataGenerator(\n",
        "  rescale=1/255.0,\n",
        "  rotation_range=20,\n",
        "  zoom_range=0.05,\n",
        "  width_shift_range=0.1,\n",
        "  height_shift_range=0.1,\n",
        "  shear_range=0.05,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=True,\n",
        "  fill_mode=\"nearest\")\n",
        "\n",
        "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
        "\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "  TRAIN_PATH,\n",
        "  class_mode=\"categorical\",\n",
        "  target_size=(48,48),\n",
        "  color_mode=\"rgb\",\n",
        "  shuffle=True,\n",
        "  batch_size=BS)\n",
        "valGen = valAug.flow_from_directory(\n",
        "  VAL_PATH,\n",
        "  class_mode=\"categorical\",\n",
        "  target_size=(48,48),\n",
        "  color_mode=\"rgb\",\n",
        "  shuffle=False,\n",
        "  batch_size=BS)\n",
        "testGen = valAug.flow_from_directory(\n",
        "  TEST_PATH,\n",
        "  class_mode=\"categorical\",\n",
        "  target_size=(48,48),\n",
        "  color_mode=\"rgb\",\n",
        "  shuffle=False,\n",
        "  batch_size=BS)\n",
        "\n",
        "model=CancerNet.build(width=48,height=48,depth=3,classes=2)\n",
        "opt=Adagrad(lr=INIT_LR,decay=INIT_LR/NUM_EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "M=model.fit_generator(\n",
        "  trainGen,\n",
        "  steps_per_epoch=lenTrain//BS,\n",
        "  validation_data=valGen,\n",
        "  validation_steps=lenVal//BS,\n",
        "  #class_weight=classWeight,\n",
        "  epochs= NUM_EPOCHS)\n",
        "\n",
        "print(\"Now evaluating the model\")\n",
        "testGen.reset()\n",
        "pred_indices=model.predict_generator(testGen,steps=(lenTest//BS)+1)\n",
        "\n",
        "pred_indices=np.argmax(pred_indices,axis=1)\n",
        "\n",
        "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
        "\n",
        "cm=confusion_matrix(testGen.classes,pred_indices)\n",
        "total=sum(sum(cm))\n",
        "accuracy=(cm[0,0]+cm[1,1])/total\n",
        "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "print(cm)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Specificity: {specificity}')\n",
        "print(f'Sensitivity: {sensitivity}')\n",
        "\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0,N), M.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0,N), M.history[\"loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0,N), M.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0,N), M.history[\"accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on the IDC Dataset\")\n",
        "plt.xlabel(\"Epoch No.\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig('plot.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H426YsNFzZZb",
        "outputId": "53869005-8548-45c9-e642-4bad3e176c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 159 images belonging to 2 classes.\n",
            "Found 17 images belonging to 2 classes.\n",
            "Found 44 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adagrad.py:77: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adagrad, self).__init__(name, **kwargs)\n",
            "<ipython-input-4-a10b676a65b8>:69: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  M=model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "4/4 [==============================] - 3s 320ms/step - loss: 0.7735 - accuracy: 0.6850\n",
            "Epoch 2/40\n",
            "4/4 [==============================] - 1s 307ms/step - loss: 0.5939 - accuracy: 0.7795\n",
            "Epoch 3/40\n",
            "4/4 [==============================] - 1s 301ms/step - loss: 0.6388 - accuracy: 0.7795\n",
            "Epoch 4/40\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.6088 - accuracy: 0.7344\n",
            "Epoch 5/40\n",
            "4/4 [==============================] - 1s 303ms/step - loss: 0.5534 - accuracy: 0.7953\n",
            "Epoch 6/40\n",
            "4/4 [==============================] - 1s 323ms/step - loss: 0.4579 - accuracy: 0.7953\n",
            "Epoch 7/40\n",
            "4/4 [==============================] - 1s 302ms/step - loss: 0.4809 - accuracy: 0.8268\n",
            "Epoch 8/40\n",
            "4/4 [==============================] - 1s 306ms/step - loss: 0.3955 - accuracy: 0.8189\n",
            "Epoch 9/40\n",
            "4/4 [==============================] - 1s 298ms/step - loss: 0.4271 - accuracy: 0.8268\n",
            "Epoch 10/40\n",
            "4/4 [==============================] - 2s 435ms/step - loss: 0.4763 - accuracy: 0.8268\n",
            "Epoch 11/40\n",
            "4/4 [==============================] - 2s 375ms/step - loss: 0.3349 - accuracy: 0.8740\n",
            "Epoch 12/40\n",
            "4/4 [==============================] - 1s 305ms/step - loss: 0.3753 - accuracy: 0.8740\n",
            "Epoch 13/40\n",
            "4/4 [==============================] - 1s 303ms/step - loss: 0.3179 - accuracy: 0.8976\n",
            "Epoch 14/40\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.2641 - accuracy: 0.8976\n",
            "Epoch 15/40\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.3804 - accuracy: 0.8594\n",
            "Epoch 16/40\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.2133 - accuracy: 0.9291\n",
            "Epoch 17/40\n",
            "4/4 [==============================] - 2s 428ms/step - loss: 0.3726 - accuracy: 0.8819\n",
            "Epoch 18/40\n",
            "4/4 [==============================] - 1s 326ms/step - loss: 0.3054 - accuracy: 0.8898\n",
            "Epoch 19/40\n",
            "4/4 [==============================] - 1s 303ms/step - loss: 0.4660 - accuracy: 0.8740\n",
            "Epoch 20/40\n",
            "4/4 [==============================] - 1s 295ms/step - loss: 0.2897 - accuracy: 0.8661\n",
            "Epoch 21/40\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.3706 - accuracy: 0.8976\n",
            "Epoch 22/40\n",
            "4/4 [==============================] - 1s 299ms/step - loss: 0.2583 - accuracy: 0.9134\n",
            "Epoch 23/40\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.2666 - accuracy: 0.8976\n",
            "Epoch 24/40\n",
            "4/4 [==============================] - 1s 308ms/step - loss: 0.1836 - accuracy: 0.9370\n",
            "Epoch 25/40\n",
            "4/4 [==============================] - 1s 307ms/step - loss: 0.2914 - accuracy: 0.8819\n",
            "Epoch 26/40\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.3294 - accuracy: 0.8976\n",
            "Epoch 27/40\n",
            "4/4 [==============================] - 1s 310ms/step - loss: 0.1909 - accuracy: 0.9213\n",
            "Epoch 28/40\n",
            "4/4 [==============================] - 1s 321ms/step - loss: 0.2179 - accuracy: 0.9141\n",
            "Epoch 29/40\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.1749 - accuracy: 0.9375\n",
            "Epoch 30/40\n",
            "4/4 [==============================] - 1s 319ms/step - loss: 0.2125 - accuracy: 0.9141\n",
            "Epoch 31/40\n",
            "4/4 [==============================] - 1s 316ms/step - loss: 0.3214 - accuracy: 0.8504\n",
            "Epoch 32/40\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.2984 - accuracy: 0.9219\n",
            "Epoch 33/40\n",
            "4/4 [==============================] - 1s 311ms/step - loss: 0.4575 - accuracy: 0.8661\n",
            "Epoch 34/40\n",
            "4/4 [==============================] - 1s 312ms/step - loss: 0.2401 - accuracy: 0.8819\n",
            "Epoch 35/40\n",
            "4/4 [==============================] - 1s 306ms/step - loss: 0.2300 - accuracy: 0.8984\n",
            "Epoch 36/40\n",
            "4/4 [==============================] - 1s 307ms/step - loss: 0.2363 - accuracy: 0.9213\n",
            "Epoch 37/40\n",
            "4/4 [==============================] - 1s 315ms/step - loss: 0.2910 - accuracy: 0.9055\n",
            "Epoch 38/40\n",
            "4/4 [==============================] - 1s 302ms/step - loss: 0.4177 - accuracy: 0.8125\n",
            "Epoch 39/40\n",
            "4/4 [==============================] - 1s 304ms/step - loss: 0.2241 - accuracy: 0.9134\n",
            "Epoch 40/40\n",
            "4/4 [==============================] - 1s 296ms/step - loss: 0.1467 - accuracy: 0.9449\n",
            "Now evaluating the model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-a10b676a65b8>:79: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  pred_indices=model.predict_generator(testGen,steps=(lenTest//BS)+1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.72        25\n",
            "           1       0.00      0.00      0.00        19\n",
            "\n",
            "    accuracy                           0.57        44\n",
            "   macro avg       0.28      0.50      0.36        44\n",
            "weighted avg       0.32      0.57      0.41        44\n",
            "\n",
            "[[25  0]\n",
            " [19  0]]\n",
            "Accuracy: 0.5681818181818182\n",
            "Specificity: 0.0\n",
            "Sensitivity: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evRZXoPAVH6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}